from pyspark.sql import SparkSession
from pyspark.sql.functions import col, regexp_replace, sum

# Start Spark session
spark = SparkSession.builder.appName("ChipotleSales").getOrCreate()

# Convert pandas DataFrame to PySpark DataFrame
chipotle_spark_df = spark.createDataFrame(df)

# Clean item_price: remove '$' and convert to float
chipotle_spark_df = chipotle_spark_df.withColumn(
    "item_price",
    regexp_replace("item_price", "\\$", "").cast("float")
)

# Calculate line_item_total = quantity * item_price
chipotle_spark_df = chipotle_spark_df.withColumn(
    "line_item_total",
    col("quantity") * col("item_price")
)

# Group by item_name, sum total sales, and sort descending
sales_per_item = chipotle_spark_df.groupBy("item_name") \
    .agg(sum("line_item_total").alias("total_sales")) \
    .orderBy(col("total_sales").desc())

# Show top 5 items by total sales
sales_per_item.show(5)

